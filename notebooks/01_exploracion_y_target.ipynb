{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320cfc72",
   "metadata": {},
   "source": [
    "# Initial Data Exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16c1d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Third-party libraries ---\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0de1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB Connection Successful!\n"
     ]
    }
   ],
   "source": [
    "# Initialize in-memory database and setup SQLite extension\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.execute(\"INSTALL sqlite;\")\n",
    "con.execute(\"LOAD sqlite;\")\n",
    "\n",
    "# Force DuckDB to treat all incoming data as strings (manual casting handled later)\n",
    "con.execute(\"SET sqlite_all_varchar=true;\")\n",
    "\n",
    "# Attach the local database file as the 'edtech' schema\n",
    "con.execute(\"ATTACH '../data/raw/enkeleksamen_case.db' AS edtech (TYPE SQLITE);\")\n",
    "\n",
    "print(\"DuckDB Connection Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20599560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c920b1993d4a7c8769ad0f53d31833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablesd:\n",
      "                      name\n",
      "0               _metadata\n",
      "1       course_categories\n",
      "2       course_progresses\n",
      "3                 courses\n",
      "4       lesson_progresses\n",
      "5                 lessons\n",
      "6          master_lessons\n",
      "7                payments\n",
      "8   product_viewed_events\n",
      "9            quiz_answers\n",
      "10  quiz_question_answers\n",
      "11         quiz_questions\n",
      "12                quizzes\n",
      "13                ratings\n",
      "14       signed_in_events\n",
      "15        specialisations\n",
      "16               students\n",
      "17          subscriptions\n",
      "18                 themes\n",
      "19                 topics\n",
      "20           universities\n",
      "21                 videos\n"
     ]
    }
   ],
   "source": [
    "# Check all tables\n",
    "tablas = con.sql(\"SHOW TABLES FROM edtech\").df()\n",
    "print(\"Tablesd:\\n\", tablas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b744b43",
   "metadata": {},
   "source": [
    "## Ground Truth\n",
    "The goal of this initial phase is to define our Target Variable (Ground Truth).\n",
    "\n",
    "Since we lack actual exam grades, we rely on the core business hypothesis: repurchasing a course strongly indicates a failed exam. Our first step is to explore the subscriptions table to flag students with multiple purchases for the same course.\n",
    "\n",
    "However, relying solely on this rule introduces a severe bias. A student who buys a course but never interacts with it (0% progress), only to repurchase it later, represents a drop-out or postponement, not a learning failure. To prevent this, we cross-reference our data with the course_progresses table. By filtering out students with zero progress on their first attempt, we ensure our model learns exclusively from users who actually tried to study but still failed. This crucial quality filter drastically reduces false positives in our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3831f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas en 'subscriptions':\n",
      "     column_name column_type\n",
      "0            id      BIGINT\n",
      "1    student_id      BIGINT\n",
      "2     course_id      BIGINT\n",
      "3    payment_id      BIGINT\n",
      "4          tier     VARCHAR\n",
      "5  amount_cents      BIGINT\n",
      "6          from     VARCHAR\n",
      "7            to     VARCHAR\n",
      "8    created_at     VARCHAR\n",
      "9    updated_at     VARCHAR\n"
     ]
    }
   ],
   "source": [
    "# Tables colums - suscription table\n",
    "columnas_subs = con.sql(\"DESCRIBE edtech.subscriptions\").df()\n",
    "print(\"\\nColumns in  'subscriptions':\\n\", columnas_subs[['column_name', 'column_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3efdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas en 'course_progresses':\n",
      "        column_name column_type\n",
      "0        course_id      BIGINT\n",
      "1       student_id      BIGINT\n",
      "2  course_progress      BIGINT\n"
     ]
    }
   ],
   "source": [
    "# colunm progress courses - table \n",
    "columnas_prog = con.sql(\"DESCRIBE edtech.course_progresses\").df()\n",
    "print(\"\\nColumn in 'course_progresses':\\n\", columnas_prog[['column_name', \n",
    "                                                             'column_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Columns in 'courses' ---\n",
      "             column_name column_type\n",
      "0                     id      BIGINT\n",
      "1                  title     VARCHAR\n",
      "2     course_category_id      BIGINT\n",
      "3              exam_date     VARCHAR\n",
      "4     silver_price_cents      BIGINT\n",
      "5       gold_price_cents      BIGINT\n",
      "6    diamond_price_cents      BIGINT\n",
      "7          lessons_count      BIGINT\n",
      "8   quiz_questions_count      BIGINT\n",
      "9               duration      BIGINT\n",
      "10                active      BIGINT\n",
      "11           purchasable      BIGINT\n",
      "12                status     VARCHAR\n",
      "13            created_at     VARCHAR\n"
     ]
    }
   ],
   "source": [
    "# Inspect 'courses' (To find the exam date)\n",
    "columnas_courses = con.sql(\"DESCRIBE edtech.courses\").df()\n",
    "print(\"\\n--- Columns in 'courses' ---\")\n",
    "print(columnas_courses[['column_name', 'column_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0deb8",
   "metadata": {},
   "source": [
    "Before defining our Target Variable, we need to inspect the exact schema and data types\n",
    " of our core tables: subscriptions, course_progresses, and courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f31875f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample record from 'subscriptions' ---\n",
      "       id student_id course_id payment_id    tier amount_cents  \\\n",
      "0  150063      35422        50     182126  silver        69900   \n",
      "\n",
      "                         from                          to  \\\n",
      "0  2023-01-01 08:58:42.997865  2022-12-31 09:28:22.154166   \n",
      "\n",
      "                   created_at                  updated_at  \n",
      "0  2023-01-01 08:58:42.999408  2023-07-03 21:01:05.635181  \n"
     ]
    }
   ],
   "source": [
    "# Peek at a real record to understand the data format\n",
    "ejemplo_subs = con.sql(\"SELECT * FROM edtech.subscriptions LIMIT 1\").df()\n",
    "print(\"\\n--- Sample record from 'subscriptions' ---\")\n",
    "print(ejemplo_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c047231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample record: 'course_progresses' ---\n",
      "  course_id student_id course_progress\n",
      "0       448      98047              32\n",
      "\n",
      "--- Sample record: 'courses' ---\n",
      "  id                         title course_category_id   exam_date  \\\n",
      "0  1  MikroÃ¸konomi - Eldre versjon                 11  2022-12-31   \n",
      "\n",
      "  silver_price_cents gold_price_cents diamond_price_cents lessons_count  \\\n",
      "0              99900           119800              219700            60   \n",
      "\n",
      "  quiz_questions_count duration active purchasable status  \\\n",
      "0                   70        0  False       False   None   \n",
      "\n",
      "                   created_at  \n",
      "0  2016-08-01 07:17:22.607308  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Sample record: 'course_progresses' ---\")\n",
    "print(con.sql(\"SELECT * FROM edtech.course_progresses LIMIT 1\").df())\n",
    "\n",
    "print(\"\\n--- Sample record: 'courses' ---\")\n",
    "print(con.sql(\"SELECT * FROM edtech.courses LIMIT 1\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba6f66",
   "metadata": {},
   "source": [
    "## Target Variable (Ground Truth) Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e42212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Analytical Cohort Size: 75709 student-course pairs\n",
      "\n",
      "Target Variable Distribution (0 = Passed, 1 = Failed/Repurchased):\n",
      "target_reprobado\n",
      "0    88.153324\n",
      "1    11.846676\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Cohort successfully saved to data/processed/cohort_target.parquet!\n"
     ]
    }
   ],
   "source": [
    "# We use TRY_CAST to handle dirty data like \"NaT\" strings in dates\n",
    "query_cohort = \"\"\"\n",
    "WITH RankedSubscriptions AS (\n",
    "    -- 1. Sort purchases per student and course to find the first attempt\n",
    "    SELECT \n",
    "        TRY_CAST(student_id AS BIGINT) AS student_id,\n",
    "        TRY_CAST(course_id AS BIGINT) AS course_id,\n",
    "        TRY_CAST(created_at AS TIMESTAMP) AS purchase_date,\n",
    "        ROW_NUMBER() OVER(PARTITION BY student_id, course_id ORDER BY TRY_CAST(created_at AS TIMESTAMP) ASC) as attempt_num\n",
    "    FROM edtech.subscriptions\n",
    "),\n",
    "FirstAttempts AS (\n",
    "    -- 2. Isolate the very first purchase attempt\n",
    "    SELECT student_id, course_id, purchase_date\n",
    "    FROM RankedSubscriptions\n",
    "    WHERE attempt_num = 1\n",
    "),\n",
    "Retakes AS (\n",
    "    -- 3. Identify students who repurchased (Target = 1)\n",
    "    SELECT DISTINCT student_id, course_id\n",
    "    FROM RankedSubscriptions\n",
    "    WHERE attempt_num > 1\n",
    ")\n",
    "-- 4. Join everything and calculate the intervention date\n",
    "SELECT \n",
    "    f.student_id,\n",
    "    f.course_id,\n",
    "    f.purchase_date,\n",
    "    TRY_CAST(c.exam_date AS TIMESTAMP) AS exam_date,\n",
    "    \n",
    "    -- The Point-in-Time limit: 14 days before the exam BCONDITION--------\n",
    "    TRY_CAST(c.exam_date AS TIMESTAMP) - INTERVAL 14 DAY AS intervention_date,\n",
    "    \n",
    "    -- Target Label: 1 if repurchased, 0 if not ----- TARGETTTT----\n",
    "    CASE WHEN r.student_id IS NOT NULL THEN 1 ELSE 0 END AS target_reprobado,\n",
    "    \n",
    "    -- Course progress for the quality filter\n",
    "    TRY_CAST(cp.course_progress AS BIGINT) AS final_progress\n",
    "    \n",
    "FROM FirstAttempts f\n",
    "LEFT JOIN Retakes r \n",
    "  ON f.student_id = r.student_id AND f.course_id = r.course_id\n",
    "LEFT JOIN edtech.courses c \n",
    "  ON f.course_id = TRY_CAST(c.id AS BIGINT)\n",
    "LEFT JOIN edtech.course_progresses cp \n",
    "  ON f.student_id = TRY_CAST(cp.student_id AS BIGINT) \n",
    " AND f.course_id = TRY_CAST(cp.course_id AS BIGINT)\n",
    "  \n",
    "-- Quality Filter: Only keep students who actually studied (>0 progress) and have a valid exam date\n",
    "WHERE TRY_CAST(cp.course_progress AS BIGINT) > 0 \n",
    "  AND TRY_CAST(c.exam_date AS TIMESTAMP) IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query in DuckDB\n",
    "df_cohort = con.sql(query_cohort).df()\n",
    "\n",
    "print(f\"Total Analytical Cohort Size: {len(df_cohort)} student-course pairs\")\n",
    "print(\"\\nTarget Variable Distribution (0 = Passed, 1 = Failed/Repurchased):\")\n",
    "print(df_cohort['target_reprobado'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Save the cohort to a parquet file for the next phase\n",
    "df_cohort.to_parquet('../data/processed/cohort_target.parquet')\n",
    "print(\"\\nCohort successfully saved to data/processed/cohort_target.parquet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df42c09",
   "metadata": {},
   "source": [
    "## Feature Engineering (Behavioral Metrics)\n",
    "\n",
    "Extract learning behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2931f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Columns in 'lesson_progresses' ---\n",
      "  column_name column_type\n",
      "0  student_id     VARCHAR\n",
      "1   lesson_id     VARCHAR\n",
      "2    progress     VARCHAR\n",
      "3  created_at     VARCHAR\n",
      "4  updated_at     VARCHAR\n",
      "\n",
      "--- Sample Record ---\n",
      "  student_id lesson_id progress                  created_at  \\\n",
      "0     101098      8771      100  2026-02-01 00:19:21.634224   \n",
      "\n",
      "                   updated_at  \n",
      "0  2026-02-01 00:19:21.634224  \n",
      "\n",
      "--- Columns in 'quiz_question_answers' ---\n",
      "        column_name column_type\n",
      "0        student_id     VARCHAR\n",
      "1  quiz_question_id     VARCHAR\n",
      "2           attempt     VARCHAR\n",
      "3           verdict     VARCHAR\n",
      "4         lesson_id     VARCHAR\n",
      "5        created_at     VARCHAR\n",
      "\n",
      "--- Sample Record ---\n",
      "  student_id quiz_question_id attempt  verdict lesson_id  \\\n",
      "0      97174            12149       0  correct      <NA>   \n",
      "\n",
      "                   created_at  \n",
      "0  2024-11-04 11:44:44.370647  \n",
      "\n",
      "Quiz Example:\n",
      "  student_id quiz_question_id attempt  verdict lesson_id  \\\n",
      "0      97174            12149       0  correct      <NA>   \n",
      "\n",
      "                   created_at  \n",
      "0  2024-11-04 11:44:44.370647  \n",
      "\n",
      "Lesson Example:\n",
      "  student_id lesson_id progress                  created_at  \\\n",
      "0     101098      8771      100  2026-02-01 00:19:21.634224   \n",
      "\n",
      "                   updated_at  \n",
      "0  2026-02-01 00:19:21.634224  \n"
     ]
    }
   ],
   "source": [
    "# Inspect 'lesson_progresses' (to measure the student's pace in terms of progress)\n",
    "lesson_columns = con.sql(\"DESCRIBE edtech.lesson_progresses\").df()\n",
    "print(\"--- Columns in 'lesson_progresses' ---\")\n",
    "print(lesson_columns[['column_name', 'column_type']])\n",
    "print(\"\\n--- Sample Record ---\")\n",
    "print(con.sql(\"SELECT * FROM edtech.lesson_progresses LIMIT 1\").df())\n",
    "\n",
    "# Inspect 'quiz_question_answers' (to measure success/mastery)\n",
    "quiz_columns = con.sql(\"DESCRIBE edtech.quiz_question_answers\").df()\n",
    "print(\"\\n--- Columns in 'quiz_question_answers' ---\")\n",
    "print(quiz_columns[['column_name', 'column_type']])\n",
    "print(\"\\n--- Sample Record ---\")\n",
    "print(con.sql(\"SELECT * FROM edtech.quiz_question_answers LIMIT 1\").df())\n",
    "\n",
    "# Summary Examples\n",
    "print(\"\\nQuiz Example:\")\n",
    "print(con.sql(\"SELECT * FROM edtech.quiz_question_answers LIMIT 1\").df())\n",
    "print(\"\\nLesson Example:\")\n",
    "print(con.sql(\"SELECT * FROM edtech.lesson_progresses LIMIT 1\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf912fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb46c88c4874fe89e6a53868fee7e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Matrix Completed ---\n",
      "Total Rows: 75709\n",
      "\n",
      "Sample of our Machine Learning variables:\n",
      "   student_id  course_id  target_reprobado  lessons_started_count  \\\n",
      "0       96303        203                 0                    112   \n",
      "1       99101        203                 0                      6   \n",
      "2       96637        127                 0                    116   \n",
      "3       96966        127                 0                    134   \n",
      "4       97134        155                 0                    167   \n",
      "\n",
      "   avg_lesson_progress  total_quiz_attempts  overall_correct_rate  \\\n",
      "0           100.000000                  169              1.000000   \n",
      "1           100.000000                    5              1.000000   \n",
      "2           100.000000                  182              1.000000   \n",
      "3            99.253731                  207              1.000000   \n",
      "4            98.508982                  284              0.961268   \n",
      "\n",
      "   first_attempt_correct_rate  days_active_before_intervention  \n",
      "0                    1.000000                               64  \n",
      "1                    1.000000                               22  \n",
      "2                    1.000000                               50  \n",
      "3                    1.000000                               40  \n",
      "4                    0.961268                               48  \n",
      "\n",
      "Feature Matrix saved to data/processed/feature_matrix.parquet!\n"
     ]
    }
   ],
   "source": [
    "# We query the Pandas DataFrame 'df_cohort' directly using DuckDB!\n",
    "query_features = \"\"\"\n",
    "WITH LessonStats AS (\n",
    "    -- 1. Calculate Pacing / Effort (Strictly before intervention date)\n",
    "    SELECT \n",
    "        c.student_id,\n",
    "        c.course_id,\n",
    "        COUNT(DISTINCT lp.lesson_id) AS lessons_started_count,\n",
    "        AVG(TRY_CAST(lp.progress AS DOUBLE)) AS avg_lesson_progress,\n",
    "        MIN(TRY_CAST(lp.created_at AS TIMESTAMP)) AS first_lesson_date\n",
    "    FROM df_cohort c\n",
    "    JOIN edtech.lesson_progresses lp \n",
    "      ON c.student_id = TRY_CAST(lp.student_id AS BIGINT)\n",
    "    WHERE TRY_CAST(lp.created_at AS TIMESTAMP) <= c.intervention_date\n",
    "    GROUP BY c.student_id, c.course_id\n",
    "),\n",
    "QuizStats AS (\n",
    "    -- 2. Calculate Mastery / Success (Strictly before intervention date)\n",
    "    SELECT \n",
    "        c.student_id,\n",
    "        c.course_id,\n",
    "        COUNT(qa.quiz_question_id) AS total_quiz_attempts,\n",
    "        \n",
    "        -- % of correct answers overall\n",
    "        AVG(CASE WHEN qa.verdict = 'correct' THEN 1.0 ELSE 0.0 END) AS overall_correct_rate,\n",
    "        \n",
    "        -- % of correct answers on the VERY FIRST attempt (True Mastery)\n",
    "        AVG(CASE WHEN qa.attempt = '0' AND qa.verdict = 'correct' THEN 1.0 \n",
    "                 WHEN qa.attempt = '0' AND qa.verdict != 'correct' THEN 0.0 \n",
    "                 ELSE NULL END) AS first_attempt_correct_rate,\n",
    "                 \n",
    "        MIN(TRY_CAST(qa.created_at AS TIMESTAMP)) AS first_quiz_date\n",
    "    FROM df_cohort c\n",
    "    JOIN edtech.quiz_question_answers qa \n",
    "      ON c.student_id = TRY_CAST(qa.student_id AS BIGINT)\n",
    "    WHERE TRY_CAST(qa.created_at AS TIMESTAMP) <= c.intervention_date\n",
    "    GROUP BY c.student_id, c.course_id\n",
    ")\n",
    "-- 3. Combine everything into our final Machine Learning Feature Matrix\n",
    "SELECT \n",
    "    c.student_id,\n",
    "    c.course_id,\n",
    "    c.target_reprobado,\n",
    "    \n",
    "    -- Replace NULLs with 0 for students who didn't interact with lessons/quizzes\n",
    "    COALESCE(l.lessons_started_count, 0) AS lessons_started_count,\n",
    "    COALESCE(l.avg_lesson_progress, 0.0) AS avg_lesson_progress,\n",
    "    COALESCE(q.total_quiz_attempts, 0) AS total_quiz_attempts,\n",
    "    COALESCE(q.overall_correct_rate, 0.0) AS overall_correct_rate,\n",
    "    COALESCE(q.first_attempt_correct_rate, 0.0) AS first_attempt_correct_rate,\n",
    "    \n",
    "    -- 4. Calculate Procrastination: Days between first activity and the intervention date\n",
    "    CASE \n",
    "        WHEN l.first_lesson_date IS NOT NULL AND q.first_quiz_date IS NOT NULL \n",
    "             THEN DATE_DIFF('day', LEAST(l.first_lesson_date, q.first_quiz_date), c.intervention_date)\n",
    "        WHEN l.first_lesson_date IS NOT NULL \n",
    "             THEN DATE_DIFF('day', l.first_lesson_date, c.intervention_date)\n",
    "        WHEN q.first_quiz_date IS NOT NULL \n",
    "             THEN DATE_DIFF('day', q.first_quiz_date, c.intervention_date)\n",
    "        ELSE 0 \n",
    "    END AS days_active_before_intervention\n",
    "\n",
    "FROM df_cohort c  \n",
    "LEFT JOIN LessonStats l \n",
    "  ON c.student_id = l.student_id AND c.course_id = l.course_id\n",
    "LEFT JOIN QuizStats q \n",
    "  ON c.student_id = q.student_id AND c.course_id = q.course_id\n",
    "\"\"\"\n",
    "\n",
    "# Execute the complex aggregation\n",
    "df_features = con.sql(query_features).df()\n",
    "\n",
    "print(\"--- Feature Matrix Completed ---\")\n",
    "print(f\"Total Rows: {len(df_features)}\")\n",
    "print(\"\\nSample of our Machine Learning variables:\")\n",
    "print(df_features.head())\n",
    "\n",
    "# Save the final matrix!\n",
    "df_features.to_parquet('../data/processed/feature_matrix.parquet')\n",
    "print(\"\\nFeature Matrix saved to data/processed/feature_matrix.parquet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7abd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edtech-student-success-pipeline (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
