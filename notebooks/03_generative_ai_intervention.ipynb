{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d8f9f3",
   "metadata": {},
   "source": [
    "# Generative AI Student Intervention\n",
    "\n",
    "Phase 3: Business Heuristics & Generative AI Intervention\n",
    "After our investigation in Phase 2, we discovered the \"Cold Start Problem\": it is nearly impossible to predict exam failure with high precision 14 or 7 days before the deadline because behavioral signals are not yet active (most students are dormant).\n",
    "The Pivot: Instead of chasing a low-precision prediction, we apply the Reciprocal Heuristic: In education, the absence of evidence of progress is evidence of risk.\n",
    "The Strategy: We segment students into three zones:\n",
    "- Safe Zone (Green): Progress > 10%. (Action: None).\n",
    "- Warning Zone (Yellow): Progress 1-9%. (Action: Low-cost nudge).\n",
    "- Dormant Zone (Red): Progress == 0%. (Action: GenAI Intervention).\n",
    "This notebook focuses on the Dormant Zone. We will use Google Gemini to generate hyper-personalized \"re-engagement\" plans for students with zero activity, helping them break their procrastination before it's too late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b5d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Import the official Google Generative AI library\n",
    "import google.generativeai as genai\n",
    "from google import genai\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ba9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment variable (from .env file)\n",
    "import os\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment. Set it in .env file\")\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25dcc9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e85e0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available models...\n",
      "- models/gemini-2.5-flash\n",
      "- models/gemini-2.5-pro\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.5-flash-preview-tts\n",
      "- models/gemini-2.5-pro-preview-tts\n",
      "- models/gemma-3-1b-it\n",
      "- models/gemma-3-4b-it\n",
      "- models/gemma-3-12b-it\n",
      "- models/gemma-3-27b-it\n",
      "- models/gemma-3n-e4b-it\n",
      "- models/gemma-3n-e2b-it\n",
      "- models/gemini-flash-latest\n",
      "- models/gemini-flash-lite-latest\n",
      "- models/gemini-pro-latest\n",
      "- models/gemini-2.5-flash-lite\n",
      "- models/gemini-2.5-flash-image\n",
      "- models/gemini-2.5-flash-lite-preview-09-2025\n",
      "- models/gemini-3-pro-preview\n",
      "- models/gemini-3-flash-preview\n",
      "- models/gemini-3.1-pro-preview\n",
      "- models/gemini-3.1-pro-preview-customtools\n",
      "- models/gemini-3-pro-image-preview\n",
      "- models/nano-banana-pro-preview\n",
      "- models/gemini-3.1-flash-image-preview\n",
      "- models/gemini-robotics-er-1.5-preview\n",
      "- models/gemini-2.5-computer-use-preview-10-2025\n",
      "- models/deep-research-pro-preview-12-2025\n",
      "- models/gemini-embedding-001\n",
      "- models/aqa\n",
      "- models/imagen-4.0-generate-001\n",
      "- models/imagen-4.0-ultra-generate-001\n",
      "- models/imagen-4.0-fast-generate-001\n",
      "- models/veo-2.0-generate-001\n",
      "- models/veo-3.0-generate-001\n",
      "- models/veo-3.0-fast-generate-001\n",
      "- models/veo-3.1-generate-preview\n",
      "- models/veo-3.1-fast-generate-preview\n",
      "- models/gemini-2.5-flash-native-audio-latest\n",
      "- models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "- models/gemini-2.5-flash-native-audio-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking available models...\")\n",
    "for m in client.models.list():\n",
    "    print(f\"- {m.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34bf173",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CANDIDATES = [\"gemini-2.0-flash\", \"gemini-flash-latest\", \"gemini-pro-latest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65d9b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Initiating GenAI connection for Student 43750...\n",
      "[LOG] Attempting generation with model: gemini-2.0-flash...\n",
      "[ERROR] Model gemini-2.0-flash failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\nPlease retry in 5.435455369s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "[LOG] Attempting generation with model: gemini-flash-latest...\n",
      "\n",
      "============================================================\n",
      "SUCCESS: INTERVENTION GENERATED (gemini-flash-latest)\n",
      "============================================================\n",
      "\n",
      "Subject: Youâ€™ve still got timeâ€”letâ€™s do this together! ðŸš€\n",
      "\n",
      "Hi there,\n",
      "\n",
      "I was just looking through my student dashboard and noticed that you haven't had a chance to dive into your course yet. First of all, I want you to take a deep breathâ€”**it is not too late.**\n",
      "\n",
      "I know exactly how it feels when a deadline starts to loom. That \"paralysis\" usually happens because the mountain looks too big to climb, so it feels easier not to start at all. But at EnkelEksamen, we specialize in helping students succeed even when time is tight. \n",
      "\n",
      "With 14 days left, you don't need to be perfect; you just need to be strategic. You still have enough time to pass this exam if we start today.\n",
      "\n",
      "To break the ice, Iâ€™ve put together a **48-hour \"Quick Start\" plan** for you. Letâ€™s forget the whole course for a second and just focus on these three tiny steps:\n",
      "\n",
      "**Step 1: The 5-Minute Entry (Today)**\n",
      "Log in to the portal right now and watch just **one** videoâ€”the \"Introduction\" or the very first lesson. Don't take notes, don't worry about the exam. Just hit play. Once you break the 0% mark, the mental barrier starts to crumble.\n",
      "\n",
      "**Step 2: Identify the \"Big Wins\" (Next 24 Hours)**\n",
      "Skip the minor details for now. Look at the course overview and pick the **three most important topics** (the ones that always show up on exams). Focus your energy there first. Getting these under your belt will give you a massive confidence boost.\n",
      "\n",
      "**Step 3: The 25-Minute Sprint (Next 48 Hours)**\n",
      "Set a timer on your phone for 25 minutes. Study until it goes off, then stop. Doing one short, focused session is infinitely better than planning a 5-hour session that never happens.\n",
      "\n",
      "Youâ€™ve already invested in yourself by getting this courseâ€”don't let that go to waste. You are more than capable of passing this, and I am going to be rooting for you every step of the way.\n",
      "\n",
      "If youâ€™re feeling stuck or donâ€™t know which chapter to hit first, just hit reply. Iâ€™m here to help you cross that finish line.\n",
      "\n",
      "Youâ€™ve got this!\n",
      "\n",
      "Warmly,\n",
      "\n",
      "**[Your Name]**\n",
      "Academic Success Coach\n",
      "EnkelEksamen\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Data Structures ---\n",
    "# Using a dictionary for the student profile (Mocking the \"Ghost Student\" found via DuckDB)\n",
    "student_profile = {\n",
    "    \"student_id\": 43750,\n",
    "    \"days_to_exam\": 14,\n",
    "    \"lessons_started\": 0,\n",
    "    \"avg_progress\": 0.0,\n",
    "    \"quizzes_attempted\": 0\n",
    "}\n",
    "\n",
    "# --- 3. Prompt Engineering Logic ---\n",
    "def get_intervention_prompt(profile: dict) -> str:\n",
    "    \"\"\"\n",
    "    Constructs a high-context prompt for the LLM to generate a \n",
    "    personalized student intervention.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    You are an empathetic, highly motivating Academic Success Coach at EnkelEksamen.\n",
    "    Your goal is to help students pass their upcoming exams and prevent course repurchases.\n",
    "    \n",
    "    STUDENT CONTEXT:\n",
    "    - Student ID: {profile['student_id']}\n",
    "    - Days remaining: {profile['days_to_exam']}\n",
    "    - Course progress: {profile['avg_progress']}%\n",
    "    \n",
    "    DIAGNOSIS:\n",
    "    This is a \"Ghost Student\" (0% progress). They are likely paralyzed by procrastination.\n",
    "    \n",
    "    REQUIREMENTS:\n",
    "    1. Tone: Warm, non-judgmental, yet encouraging.\n",
    "    2. Action Plan: Suggest a 3-step plan for the first 48 hours to break the ice.\n",
    "    3. Closing: Supportive and human.\n",
    "    \n",
    "    Generate the outreach email:\n",
    "    \"\"\"\n",
    "\n",
    "# --- 4. Resilient Execution Logic ---\n",
    "def run_student_intervention():\n",
    "    \"\"\"\n",
    "    Attempts to generate the email using a fallback mechanism across \n",
    "    different model versions to ensure high availability.\n",
    "    \"\"\"\n",
    "    prompt_text = get_intervention_prompt(student_profile)\n",
    "    \n",
    "    print(f\"[LOG] Initiating GenAI connection for Student {student_profile['student_id']}...\")\n",
    "    \n",
    "    for model_name in MODEL_CANDIDATES:\n",
    "        try:\n",
    "            print(f\"[LOG] Attempting generation with model: {model_name}...\")\n",
    "            \n",
    "            response = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt_text\n",
    "            )\n",
    "            \n",
    "            # If successful, print and exit loop\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"SUCCESS: INTERVENTION GENERATED ({model_name})\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "            print(response.text)\n",
    "            return  # Exit function after success\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Model {model_name} failed: {str(e)}\")\n",
    "            time.sleep(1)  # Brief pause before next attempt\n",
    "            continue\n",
    "\n",
    "    print(\"\\n[CRITICAL] All model candidates failed. Check API Quota or Key status.\")\n",
    "\n",
    "# --- 5. Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_student_intervention()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6f4c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edtech-student-success-pipeline (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
